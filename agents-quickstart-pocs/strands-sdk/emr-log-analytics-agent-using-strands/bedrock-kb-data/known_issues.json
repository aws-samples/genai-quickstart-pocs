{"issue_id": "emrsdk-1001", "component": "EMR SDK", "summary": "S3 Throttling Detected in EMRFS", "description": "The error code 500 Internal Error indicates that Amazon S3 could not handle the request at that time. The error code 503 Slow Down typically indicates that the number of requests to your Amazon S3 bucket is high. For example, you can send 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix to an Amazon S3 bucket. However, Amazon S3 can return a 503 Slow Down response if your requests exceed the amount of bandwidth that's available for cross-region copying. We recommend modifying the retry strategy for Amazon S3 requests. The 'fs.s3.maxRetries' controls the retry limit for the default exponential back-off retry strategy. AIMD retry strategy can be used from EMR 6.4.0 and later.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception", "503 Slow Down", "500 Internal Error"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception 503 Slow Down 500 Internal Error", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-s3-503-slow-down", "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-emrfs-retry.html", "https://repost.aws/knowledge-center/http-5xx-errors-s3"]}
{"issue_id": "emrsdk-1002", "component": "EMR SDK", "summary": "SdkClientException Detected", "description": "This exception is thrown by the SDK (emrfs), when the service could not be contacted for a response, or when the client is unable to parse the response from the service. Check the error message to understand the underlying cause of this exception. Exceptions could also occur due to various other issues in the environment like network (failed to connect to service endpoint), DNS (unable to execute HTTP request), etc.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.SdkClientException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.SdkClientException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1003", "component": "EMR SDK", "summary": "EMRFS ConsistencyException Detected", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) on the EMR cluster. For every Amazon S3 operation, EMRFS checks the metadata for information about the set of objects in consistent view. If EMRFS finds that Amazon S3 is inconsistent during one of these operations, it retries the operation according to parameters defined in the emrfs-site configuration properties. After EMRFS exhausts the retries, it either throws 'ConsistencyException' or logs the exception. However, with the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.consistency.exception.ConsistencyException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.consistency.exception.ConsistencyException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1004", "component": "EMR SDK", "summary": "MultiObjectDeleteException Detected", "description": "This error can occur when any of the keys in the POST request fails to delete and internally throws an error. The recommended practice would be to retry the full request. Newer versions of EMRFS on EMR release labels on/above EMR 6.16 will have the necessary logic to handle these retries (configurable via fs.s3.delete.retryCount). We recommend to upgrade to a newer EMR version or reach out to AWS Support.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.MultiObjectDeleteException", "One or more objects could not be deleted", "Status Code: 200"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.MultiObjectDeleteException One or more objects could not be deleted Status Code: 200", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1005", "component": "EMR SDK", "summary": "AbortedException Detected", "description": "AbortedException is generally thrown when the SDK handles an InterruptedException (example: the thread was signaled to stop doing work). Check the stack trace to understand the cause of this issue. Verify if the corresponding JVM was killed by OOM.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.AbortedException", "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.timers.client.SdkInterruptedException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.AbortedException com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.http.timers.client.SdkInterruptedException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1006", "component": "EMR SDK", "summary": "ProvisionException Detected in EMRFS", "description": "This message is typically seen when EMRFS consistency view is enabled on EMR. See the Caused by to understand the root cause. We recommend disabling consistent view as it is no longer needed by EMR. In the emrfs-site.xml, if parameters are not supported or set improperly, it will raise this misleading error without any useful information. Disable each EMRFS parameter one by one in the emrfs-site.xml file and check which parameter is causing this issue.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.google.inject.ProvisionException.getMessage", "ArrayIndexOutOfBoundsException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.google.inject.ProvisionException.getMessage ArrayIndexOutOfBoundsException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1007", "component": "EMR SDK", "summary": "AWSSecurityTokenServiceException Detected", "description": "This is a base exception for all service exceptions thrown by AWS Security Token Service (STS) when EMRFS is making a call to Amazon S3. Check the relevant message followed by this exception in the logs to understand the root cause. Check relevant IAM permissions of the IAM role/user making this call.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.securitytoken.model.AWSSecurityTokenServiceException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.securitytoken.model.AWSSecurityTokenServiceException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1008", "component": "EMR SDK", "summary": "RetriableEntityStoreException Detected in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster. In this case, EMRFS uses Amazon DynamoDB to store metadata. If Amazon DynamoDB is throttled or if there is any issue accessing Amazon DynamoDB, this exception is usually observed. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.dynamodb.impl.exception.RetriableEntityStoreException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.dynamodb.impl.exception.RetriableEntityStoreException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1009", "component": "EMR SDK", "summary": "AmazonDynamoDBException Detected in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster. In this case, EMRFS uses Amazon DynamoDB to store metadata. If there are any issues when making Amazon DynamoDB API calls, this exception is usually observed. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.AmazonDynamoDBException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.AmazonDynamoDBException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1010", "component": "EMR SDK", "summary": "ProvisionedThroughputExceededException in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster. In this case, EMRFS uses Amazon DynamoDB to store metadata. If there are ProvisionedThroughputExceeded issues when making Amazon DynamoDB API calls, this exception is usually observed. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.ProvisionedThroughputExceededException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.ProvisionedThroughputExceededException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1011", "component": "EMR SDK", "summary": "HttpHostConnectException Detected in EMRFS", "description": "This exception happens when there is a connection timed out to a host. Check the host logs and see if the relevant JVM is listening on the relevant port got restarted or if it is still running.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.HttpHostConnectException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.HttpHostConnectException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1012", "component": "EMR SDK", "summary": "EntityStoreException detected in EMRFS", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) on the EMR cluster and when EMRFS is trying to access metadata on Amazon DynamoDB, this exception can be seen. Check if the Amazon DynamoDB table exists and has the correct schema. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.dynamodb.impl.exception.EntityStoreException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.dynamodb.impl.exception.EntityStoreException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1013", "component": "EMR SDK", "summary": "FileDeletedInMetadataNotFoundException Detected", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) on the EMR cluster and when the metadata entry in Amazon DynamoDB is not found. This is typically seen when using s3distcp. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.consistency.exception.FileDeletedInMetadataNotFoundException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.consistency.exception.FileDeletedInMetadataNotFoundException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1014", "component": "EMR SDK", "summary": "ConnectTimeoutException Detected", "description": "This exception happens when there is a connection timed out to a host. Check the host logs and see if the relevant JVM listening on the relevant port got restarted or if it is still running.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.ConnectTimeoutException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.ConnectTimeoutException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1015", "component": "EMR SDK", "summary": "InternalServerErrorException Detected in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster and when Amazon DynamoDB is returning 5xx errors. 5xx errors are common due to the distributed nature of Amazon DynamoDB. However, if you have noticed a significant rise in the number of errors, please reach out to AWS support. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.InternalServerErrorException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.InternalServerErrorException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-plan-consistent-view.html"]}
{"issue_id": "emrsdk-1016", "component": "EMR SDK", "summary": "ConnectionPoolTimeoutException Detected in EMRFS", "description": "The error usually means that a request cannot get a connection from the pool within the specified maximum time. This can be due to a high request rate. Consider taking any of the following actions to mitigate the issue: increase max connections, increase acquire timeout, or slowing the request rate. If the above mechanisms are not able to fix the issue, try smoothing out your requests so that large traffic bursts cannot overload the client, being more efficient with the number of times you need to call AWS, or by increasing the number of hosts sending requests. From the EMR perspective, increasing the EMRFS Config 'fs.s3.maxConnections' may help. Enabling DEBUG on the PoolingHttpClientConnectionManager class may be required to monitor connections.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.ConnectionPoolTimeoutException", "Timeout waiting for connection from pool"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.conn.ConnectionPoolTimeoutException Timeout waiting for connection from pool", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1017", "component": "EMR SDK", "summary": "NoHttpResponseException Detected in EMRFS", "description": "This error indicates the SDK tried to establish a connection to the Amazon S3 endpoint but was not able to. It can be caused by network connectivity issues such as high latency. The EmrFs library on/after EMR 6.14 exposes the configuration setting 'fs.s3.connection.maxIdleMilliSeconds' to define the maximum time in milliseconds an open connection will be allowed to live. The recommendation is to set the value to 5 seconds: fs.s3.connection.maxIdleMilliSeconds=5000. From the Java docs: setConnectionMaxIdleMillis(long connectionMaxIdleMillis) - Sets the maximum amount of time that an idle connection may sit in the connection pool and still be eligible for reuse.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.NoHttpResponseException", "The target server failed to respond"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.NoHttpResponseException The target server failed to respond", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1018", "component": "EMR SDK", "summary": "ResourceNotFoundException is detected in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster and when the Amazon DynamoDB table is not present. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.ResourceNotFoundException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.dynamodbv2.model.ResourceNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1019", "component": "EMR SDK", "summary": "AWSKMSException Detected in EMRFS", "description": "This error indicates that the Amazon S3 objects that EMRFS is trying to access are encrypted using AWS Key Management Service (KMS). Check the Amazon S3 bucket/object permissions and relevant KMS policies using the AWS Console ('Key Users').", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.kms.model.AWSKMSException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.kms.model.AWSKMSException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1020", "component": "EMR SDK", "summary": "SecretAgentClientException Detected", "description": "This error indicates that EMRFS failed to retrieve credentials from the EMR secret agent for the Amazon S3 request. Check the 'emrsecretagent' configuration and logs. If you are using AWS Lake Formation, check the 'GetDataAccess' API call in CloudTrail and explore the permissions.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.emr.secretagent.client.model.SecretAgentClientException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.emr.secretagent.client.model.SecretAgentClientException", "knowledge_center_links": [""]}
{"issue_id": "emrsdk-1021", "component": "EMR SDK", "summary": "FileDirectoryMismatchException detected in EMRFS Consistent View", "description": "This error is thrown when EMRFS Consistent View is enabled (fs.s3.consistent) in the EMR cluster. This error usually happens when a particular Amazon S3 key is marked as a directory in the metadata but it is actually an object. With the release of Amazon S3 strong read-after-write consistency on December 1, 2020, you no longer need to use EMRFS consistent view (EMRFS CV) in your Amazon EMR clusters.", "keywords": ["com.amazon.ws.emr.hadoop.fs.consistency.FileDirectoryMismatchException"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.consistency.FileDirectoryMismatchException", "knowledge_center_links": [""]}
{"issue_id": "emrservice-1001", "component": "EMR Service", "summary": "Node Provisioning Issues", "description": "This exception is an indication that node provisioning using Puppet and/or BigTop is failing. This could be due to an incorrect configuration (including security configurations, expired certificates), incompatible configs/packages in bootstrap actions that can cause conflicts, and/or open-source application installation issues.", "keywords": ["com.amazonaws.emr.node.provisioner.puppet.api.PuppetException"], "keywords_text": "com.amazonaws.emr.node.provisioner.puppet.api.PuppetException", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-application-provisioning-error"]}
{"issue_id": "emrservice-1002", "component": "EMR Service", "summary": "Package Installation Failure During Node Provisioning", "description": "This exception is an indication that Yum is unable to download or install packages during node provisioning due to 1) Space constraints on the file system, 2) Access restrictions to the Amazon S3 Yum repository, or 3) Package incompatibility introduced by bootstrap actions.", "keywords": ["com.amazonaws.emr.node.provisioner.yum.api.YumException"], "keywords_text": "com.amazonaws.emr.node.provisioner.yum.api.YumException", "knowledge_center_links": ["https://repost.aws/knowledge-center/ec2-troubleshoot-yum-errors-al1-al2"]}
{"issue_id": "emrservice-1003", "component": "EMR Service", "summary": "Amazon EC2 AMI Linux 2 amazon-linux-extras basearch Error", "description": "This exception can be observed in Amazon Linux 2 AMIs. This issue can occur due to the 'basearch' OS parameter modification for Yum variables. It may also be observed when there are access restrictions to the Amazon S3 Yum repository. We recommend validating the VPC, DHCP, or proxy settings. It may also indicate custom AMI issues.", "keywords": ["com.amazonaws.emr.node.provisioner.install.amazonlinuxextras.AmazonLinuxExtrasException"], "keywords_text": "com.amazonaws.emr.node.provisioner.install.amazonlinuxextras.AmazonLinuxExtrasException", "knowledge_center_links": ["https://repost.aws/knowledge-center/ec2-al1-al2-update-yum-without-internet"]}
{"issue_id": "emrservice-1004", "component": "EMR Service", "summary": "Amazon S3 Lake Formation Access Issues", "description": "This exception may occur when the Amazon S3 path being accessed by EMR is not registered as a data lake location. Also, ensure that a trust policy is added to allow Lake Formation to assume the runtime role.", "keywords": ["com.amazonaws.emr.recordserver.remote.RecordServerException"], "keywords_text": "com.amazonaws.emr.recordserver.remote.RecordServerException", "knowledge_center_links": ["https://docs.aws.amazon.com/lake-formation/latest/dg/tut-register.html"]}
{"issue_id": "emrservice-1005", "component": "EMR Service", "summary": "Secret Agent Exception", "description": "On a managed scaling enabled cluster, a newly added node is deemed ready when the YARN NodeManager is started on that node. If the Secret Agent component is not up and running before the NodeManager is started on a node, a job assigned to that node will fail as the Secret Agent is not reachable. To address this, changes were made to EMR 6.12 (and above) to ensure that the Secret Agent is running and ready before the NodeManager is started.", "keywords": ["com.amazonaws.emr.secretagent.client.model.SecretAgentClientException"], "keywords_text": "com.amazonaws.emr.secretagent.client.model.SecretAgentClientException", "knowledge_center_links": [""]}
{"issue_id": "emrservice-1006", "component": "EMR Service", "summary": "Incorrect Configuration Exception", "description": "1) In High Availability (HA) clusters, the EMR service team recommends setting the properties using the following scheme: {'Classification': 'yarn-site', 'Properties': {'yarn.node-labels.fs-store.root-dir': 'file:///apps/yarn/nodelabels'}} This should help resolve the issue. 2) The reconfiguration on EMR clusters is stuck or failing on nodes due to Apache Knox or other third-party services generating some UIDs that are larger than the maximum value, and then the InstanceController can't take the value and fails with this exception. The issue was fixed in EMR 6.10 and above. You can avoid these issues by migrating to EMR 6.11 or above.", "keywords": ["com.amazonaws.emr.node.provisioner.config.ConfigException"], "keywords_text": "com.amazonaws.emr.node.provisioner.config.ConfigException", "knowledge_center_links": [""]}
{"issue_id": "emrservice-1007", "component": "EMR Service", "summary": "EMR Scaling Service Side Issue", "description": "The root cause of the issue is usually related to a bug in the communications protocol between Amazon EC2 instances in an EMR cluster. The bug has been fixed in all AWS regions. AWS is taking steps to prevent a recurrence of this issue. Specifically, AWS is adding automated tests to detect the issue.", "keywords": ["com.amazonaws.emr.tls.trustmanager.ClusterMembershipCertificateException"], "keywords_text": "com.amazonaws.emr.tls.trustmanager.ClusterMembershipCertificateException", "knowledge_center_links": [""]}
{"issue_id": "emrservice-1008", "component": "EMR Service", "summary": "Ranger / Lake Formation Authorization Issues", "description": "This exception can be an indication of a broader AWS Lake Formation permission issue, invalid Ranger plugin parameters, or EMR clusters using a runtime role with limited access.", "keywords": ["com.amazonaws.emr.recordserver.remote.AuthorizationException"], "keywords_text": "com.amazonaws.emr.recordserver.remote.AuthorizationException", "knowledge_center_links": [""]}
{"issue_id": "emrservice-1009", "component": "EMR Service", "summary": "Incorrect Custom AMI Base Image", "description": "This exception indicates that the EMR custom AMI practices are not being followed, notably when an EMR AMI is used to build the Custom AMI, and ensuring that the AMI version matches the EMR release version.", "keywords": ["com.amazonaws.emr.node.provisioner.install.packaging.InvalidPackageGroupNameException"], "keywords_text": "com.amazonaws.emr.node.provisioner.install.packaging.InvalidPackageGroupNameException", "knowledge_center_links": ["https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-custom-ami.html#emr-custom-ami-considerations"]}
{"issue_id": "error-exception-fatal", "component": "General Error", "summary": "Error/Exception Detected in the EMR Logs", "description": "An error or exception was detected in the EMR logs. Check the message followed by the error to troubleshoot further.", "keywords": ["ERROR", "EXCEPTION", "FATAL"], "keywords_text": "ERROR EXCEPTION FATAL", "knowledge_center_links": null}
{"issue_id": "hdfs-1001", "component": "Hadoop HDFS", "summary": "Blocks Were Missing or Could Not Obtain Block", "description": "This may be caused due to data node failures, replication issues, accidental deletions, or because of a faulty NameNode switch. Hadoop tools such as 'hdfs fsck' can be used to check the integrity of the file system. Amazon CloudWatch metrics can be monitored to understand when corrupt or missing blocks started to happen, and HDFS logs can be explored during that timeline.", "keywords": ["org.apache.hadoop.hdfs.BlockMissingException"], "keywords_text": "org.apache.hadoop.hdfs.BlockMissingException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1002", "component": "Hadoop HDFS", "summary": "HDFS NameNode Went into Safe Mode", "description": "Safe mode for the NameNode is a read-only mode for the Hadoop Distributed File System (HDFS) cluster. In safe mode, you can't make any modifications to the file system or blocks. Check why the NameNode went into safe mode. Ideally, it should come out of safe mode when the configured criteria for exiting safe mode is met (example: replaying edit logs). If the NameNode is stuck in safe mode for an extended period, you will need to check the logs to understand the reasons.", "keywords": ["org.apache.hadoop.hdfs.server.namenode.SafeModeException"], "keywords_text": "org.apache.hadoop.hdfs.server.namenode.SafeModeException", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-namenode-turn-off-safemode"]}
{"issue_id": "hdfs-1003", "component": "Hadoop HDFS", "summary": "NameNode Stuck in a Loop While Replicating a Non-Existent Block/File", "description": "The NameNode sometimes gets stuck in a loop replicating when there is an abrupt exit or shutdown of the client who is copying the file, or suddenly the NameNode would switch to safe mode stating no blocks can be written to HDFS.", "keywords": ["org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException"], "keywords_text": "org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1004", "component": "Hadoop HDFS", "summary": "NameNode Entering into Safe Mode", "description": "When the NameNode enters into safe mode, this exception will be seen. We recommend checking the NameNode logs to see the reason for the NameNode going into safe mode.", "keywords": ["org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException"], "keywords_text": "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-namenode-turn-off-safemode"]}
{"issue_id": "hdfs-1005", "component": "Hadoop HDFS", "summary": "NameNode Could Not Communicate with DataNode", "description": "If there is any communication problem between the NameNode and a DataNode, then you typically see this exception, and if we have only one DataNode, then the NameNode will not come up.", "keywords": ["org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException"], "keywords_text": "org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1006", "component": "Hadoop HDFS", "summary": "NameNode Storage Directory is Inaccessible or Inconsistent", "description": "org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /mnt/namenode is in an inconsistent state: storage directory does not exist or is not accessible.", "keywords": ["org.apache.hadoop.hdfs.server.common.InconsistentFSStateException"], "keywords_text": "org.apache.hadoop.hdfs.server.common.InconsistentFSStateException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1007", "component": "Hadoop HDFS", "summary": "File is Still Being Written to HDFS", "description": "You see 'Cannot obtain block length for LocatedBlock', which means the file is still in the being-written state, i.e., it has not been closed yet, and the reader cannot successfully identify its current length by communicating with the corresponding DataNodes.", "keywords": ["org.apache.hadoop.hdfs.CannotObtainBlockLengthException"], "keywords_text": "org.apache.hadoop.hdfs.CannotObtainBlockLengthException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1008", "component": "Hadoop HDFS", "summary": "Could Not Replicate the Ingested Block or File", "description": "When trying to write a file at that time, if it could not replicate, we typically see this exception.", "keywords": ["org.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException"], "keywords_text": "org.apache.hadoop.hdfs.server.namenode.NotReplicatedYetException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1009", "component": "Hadoop HDFS", "summary": "JournalNodeManager Could Not Respond", "description": "If there is any issue with the JournalManager, then we will get this exception.", "keywords": ["org.apache.hadoop.hdfs.qjournal.client.QuorumException"], "keywords_text": "org.apache.hadoop.hdfs.qjournal.client.QuorumException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1010", "component": "Hadoop HDFS", "summary": "Replica Missing from the Respective Block Pool", "description": "Generally, there could be two possible reasons: ReplicaNotFound or BlockMissing.", "keywords": ["org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException"], "keywords_text": "org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1011", "component": "Hadoop HDFS", "summary": "NameNode Could Not Get the Lease on the File to Write", "description": "While data is being written to a file and is not able to write or get the lease on that file to perform write operations.", "keywords": ["org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException"], "keywords_text": "org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1012", "component": "Hadoop HDFS", "summary": "Filesystem Has Reached the Limit", "description": "Occurs when a directory has reached the maximum number of files in the filesystem with the error FSLimitException.", "keywords": ["org.apache.hadoop.hdfs.protocol.FSLimitException"], "keywords_text": "org.apache.hadoop.hdfs.protocol.FSLimitException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1013", "component": "Hadoop HDFS", "summary": "Blocks Already Exist", "description": "This indicates that the target block already exists and is not set to be recovered or overwritten.", "keywords": ["org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException"], "keywords_text": "org.apache.hadoop.hdfs.server.datanode.ReplicaAlreadyExistsException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1014", "component": "Hadoop HDFS", "summary": "Append Operation for an Existing File or Block", "description": "This indicates the NameNode is currently in the process of recovering from a failure or undergoing some maintenance.", "keywords": ["org.apache.hadoop.hdfs.protocol.RecoveryInProgressException"], "keywords_text": "org.apache.hadoop.hdfs.protocol.RecoveryInProgressException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1015", "component": "Hadoop HDFS", "summary": "Quorum Exception Where It Could Not Create", "description": "When the JournalNodes could not create a quorum.", "keywords": ["org.apache.hadoop.hdfs.qjournal.client.QuorumException.create"], "keywords_text": "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1016", "component": "Hadoop HDFS", "summary": "NameNode Could Not Replay the Edit Log", "description": "If there is any mismatch between the current log transaction ID and the future transaction ID, then we will see an exception like (Error replaying edit log at offset 0. Expected transaction ID was XXXXXXX).", "keywords": ["org.apache.hadoop.hdfs.server.namenode.EditLogInputException"], "keywords_text": "org.apache.hadoop.hdfs.server.namenode.EditLogInputException", "knowledge_center_links": [""]}
{"issue_id": "hdfs-1017", "component": "Hadoop HDFS", "summary": "When JournalNode is Not Able to Join Quorum or Has an Issue with Any Node", "description": "The call to form a quorum fails due to an issue with the process or with the node.", "keywords": ["org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException"], "keywords_text": "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1001", "component": "Hadoop YARN", "summary": "Runtime error occurs in YARN framework.", "description": "As a general-purpose exception, YarnRuntimeException can be thrown for a variety of reasons, and the specific details of the error are typically conveyed through the accompanying stack trace and error messages.", "keywords": ["org.apache.hadoop.yarn.exceptions.YarnRuntimeException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.YarnRuntimeException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1002", "component": "Hadoop YARN", "summary": "YARN-specific exceptions.", "description": "If you encounter a YarnException in your application, it's essential to inspect the specific type of exception thrown and review any accompanying stack trace or error messages. Understanding the context of the exception will help you diagnose and address the underlying issue.", "keywords": ["org.apache.hadoop.yarn.exceptions.YarnException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.YarnException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1003", "component": "Hadoop YARN", "summary": "Exception if application doesn't exist in RM", "description": "This exception is thrown on (GetApplicationAttemptReportRequest) API when the Application Attempt doesn't exist in the Application History Server.", "keywords": ["org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1004", "component": "Hadoop YARN", "summary": "Application is no longer running", "description": "This exception is thrown on (GetApplicationReportRequest) API when the Application doesn't exist in the Resource Manager (RM) and Application History Server (AHS).", "keywords": ["org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1005", "component": "Hadoop YARN", "summary": "Application requesting more memory than what YARN is authorizing to do", "description": "This exception is thrown when a resource requested via ResourceRequest in the ApplicationMasterProtocol.allocate(AllocateRequest) API is out of the range of the configured lower and upper limits on resources.", "keywords": ["org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1006", "component": "Hadoop YARN", "summary": "container launch failure in nodemanger", "description": "This exception is typically thrown when there is an issue during the execution of a container on a NodeManager in the YARN cluster. Common reasons for such exceptions include issues with resource allocation, container execution environment setup, or problems with the underlying hardware.", "keywords": ["org.apache.hadoop.yarn.server.nodemanager.containermanager.runtime.ContainerExecutionException"], "keywords_text": "org.apache.hadoop.yarn.server.nodemanager.containermanager.runtime.ContainerExecutionException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1007", "component": "Hadoop YARN", "summary": "This is the exception class indicating an error during privileged operations.", "description": "This exception is thrown when an error occurs during the execution of privileged operations related to Linux containers in the NodeManager component. Common reasons for such exceptions include issues with Linux container configurations, inadequate permissions, or problems with the underlying Linux environment.", "keywords": ["org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException"], "keywords_text": "org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1008", "component": "Hadoop YARN", "summary": "This class is associated with handling serialized exceptions within the YARN framework.", "description": "When working with YARN, exceptions might be serialized for transport between different components of the system, such as between the ResourceManager and NodeManagers or between different nodes in a YARN cluster. This process allows for the propagation of error information across the YARN framework.", "keywords": ["org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException"], "keywords_text": "org.apache.hadoop.yarn.api.records.impl.pb.SerializedExceptionPBImpl.instantiateException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1009", "component": "Hadoop YARN", "summary": "This exception is typically thrown when there is an issue related to the resource request with invalid labels in a YARN application.", "description": "Need to review the code where the resource request is being made and ensure that the labels used are valid and recognized by the YARN cluster.", "keywords": ["org.apache.hadoop.yarn.exceptions.InvalidLabelResourceRequestException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.InvalidLabelResourceRequestException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1010", "component": "Hadoop YARN", "summary": "Web application context for handling exceptions and rendering error pages.", "description": "A mechanism for handling exceptions in a consistent manner across different parts of the YARN web application.", "keywords": ["org.apache.hadoop.yarn.webapp.GenericExceptionHandler"], "keywords_text": "org.apache.hadoop.yarn.webapp.GenericExceptionHandler", "knowledge_center_links": [""]}
{"issue_id": "yarn-1011", "component": "Hadoop YARN", "summary": "invalid auxiliary service in a YARN application.", "description": "This exception is typically thrown when there is an issue related to an auxiliary (aux) service in the YARN", "keywords": ["org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.InvalidAuxServiceException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1012", "component": "Hadoop YARN", "summary": "a mechanism for handling uncaught exceptions in the YARN framework.", "description": "handling uncaught exceptions in a consistent way across YARN components.", "keywords": ["org.apache.hadoop.yarn.YarnUncaughtExceptionHandler"], "keywords_text": "org.apache.hadoop.yarn.YarnUncaughtExceptionHandler", "knowledge_center_links": [""]}
{"issue_id": "yarn-1013", "component": "Hadoop YARN", "summary": "would be thrown if there is an attempt to interact with a container that does not exist", "description": "This exception is typically thrown when there is an attempt to perform an operation on a container that cannot be found in the YARN cluster. It could be related to querying, releasing, or managing containers within your YARN application.", "keywords": ["org.apache.hadoop.yarn.exceptions.ContainerNotFoundException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.ContainerNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1014", "component": "Hadoop YARN", "summary": "Exception related to YARN web applications", "description": "it may be thrown to handle errors related to web application initialization, request processing, or other web-related functionalities.", "keywords": ["org.apache.hadoop.yarn.webapp.WebAppException"], "keywords_text": "org.apache.hadoop.yarn.webapp.WebAppException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1015", "component": "Hadoop YARN", "summary": "This exception is typically thrown when there is an issue related to an invalid request made by the Application Master in a YARN application.", "description": "The Application Master is a component responsible for negotiating resources with the ResourceManager and managing the execution of tasks in a YARN application. The InvalidApplicationMasterRequestException would be thrown if there is an attempt to make a request or perform an operation that is not valid or allowed by the YARN framework.", "keywords": ["org.apache.hadoop.yarn.exceptions.InvalidApplicationMasterRequestException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.InvalidApplicationMasterRequestException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1016", "component": "Hadoop YARN", "summary": "This exception is typically thrown when a requested resource is not found in the context of a YARN web application.", "description": "YARN web application, a 'resource' could refer to a web page, REST API endpoint, or some other entity that a user or client is attempting to access. The NotFoundException would be thrown to signal that the requested resource doesn't exist. The web application can then respond with an appropriate HTTP status code (e.g., 404 Not Found) to inform the client about the absence of the requested resource.", "keywords": ["org.apache.hadoop.yarn.webapp.NotFoundException"], "keywords_text": "org.apache.hadoop.yarn.webapp.NotFoundException", "knowledge_center_links": [""]}
{"issue_id": "yarn-1017", "component": "Hadoop YARN", "summary": "This exception is typically thrown when there is an attempt to perform an operation on an application attempt that cannot be found in the YARN cluster.", "description": "In YARN, an application attempt represents a single attempt to run a YARN application. If you encounter this exception, it may be related to querying, releasing, or managing application attempts within your YARN application.", "keywords": ["org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException"], "keywords_text": "org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "hbase-1001", "component": "HBase", "summary": "The Error Occurs When an RPC Operation Fails After Retrying for hbase.client.retries.number", "description": "Exception thrown by HTable methods when an attempt to do something (like commit changes) fails after a bunch of retries. There could be multiple factors for such errors - connection issues, regions in transition. You will need to look into the HBase master and respective region server logs.", "keywords": ["org.apache.hadoop.hbase.client.RetriesExhaustedException"], "keywords_text": "org.apache.hadoop.hbase.client.RetriesExhaustedException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/client/RetriesExhaustedException.html?is-external=true"]}
{"issue_id": "hbase-1002", "component": "HBase", "summary": "Phoenix StaleRegionBoundaryCacheException Detected", "description": "Phoenix tries to connect to the hbase:meta table by default. However, because the hbase:meta table belongs to the primary cluster, Phoenix cannot connect to the read-replica cluster. To resolve this problem, modify hbase-site.xml to point to the hbase:meta_cluster-id table that belongs to the HBase read-replica cluster.", "keywords": ["StaleRegionBoundaryCacheException", "Cache of region boundaries are out of date"], "keywords_text": "StaleRegionBoundaryCacheException Cache of region boundaries are out of date", "knowledge_center_links": [""]}
{"issue_id": "hbase-1003", "component": "HBase", "summary": "The Error Occurs When the Master Has Not Completed Its Initialization", "description": "This exception is thrown by the master when a region server was shut down and restarted so fast that the master still hasn't processed the server shutdown of the first instance, or when the master is initializing and a client calls admin operations, or when an operation is performed on a region server that is still starting. Please check the master logs to see where the initialization is stuck.", "keywords": ["org.apache.hadoop.hbase.PleaseHoldException"], "keywords_text": "org.apache.hadoop.hbase.PleaseHoldException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/PleaseHoldException.html"]}
{"issue_id": "hbase-1004", "component": "HBase", "summary": "The Error Occurs on the Client Side If the Region Where the Request Is Made Is Not Serving the Data for the Specific Region", "description": "Thrown by a region server if it is sent a request for a region it is not serving. Generally, this happens when a region is not online or is undergoing a split. You need to check for stuck procedures for the region and bypass them. In cases like this, the master moves the region to the OFFLINE state and re-assigns it to a different RegionServer. Please retry your operation. If the NotServingRegionException is logged at the ERROR level, it means RetriesExhausted, and the region's health would need to be verified.", "keywords": ["org.apache.hadoop.hbase.NotServingRegionException"], "keywords_text": "org.apache.hadoop.hbase.NotServingRegionException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/NotServingRegionException.html"]}
{"issue_id": "hbase-1005", "component": "HBase", "summary": "This Exception Depicts a Client-Side Timeout", "description": "Client-side call timeout. Try checking the Region Server logs mentioned in the error. Some possible causes could be exceptions like CallQueueTooBigException at the Region Server logs. Increasing timeouts can also be helpful.", "keywords": ["org.apache.hadoop.hbase.ipc.CallTimeoutException"], "keywords_text": "org.apache.hadoop.hbase.ipc.CallTimeoutException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/ipc/CallTimeoutException.html"]}
{"issue_id": "hbase-1006", "component": "HBase", "summary": "HBase RemoteWithExtrasException Detected", "description": "A RemoteException with some extra information. If the source exception was a DoNotRetryIOException, isDoNotRetry() will return true. A RemoteException hosts exceptions we got from the server. You will need to look at the remote exception. The exception would carry details of another exception that is occurring. The exception provides details of the error coming from the remote host.", "keywords": ["org.apache.hadoop.hbase.ipc.RemoteWithExtrasException"], "keywords_text": "org.apache.hadoop.hbase.ipc.RemoteWithExtrasException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/ipc/RemoteWithExtrasException.html"]}
{"issue_id": "hbase-1007", "component": "HBase", "summary": "HBase RetriesExhaustedWithDetailsException Provides Details on the Rowkey Giving a Problem", "description": "This subclass of RetriesExhaustedException is thrown when we have more information about which rows were causing which exceptions on what servers. You can call mayHaveClusterIssues(), and if the result is false, you have input error problems; otherwise, you may have cluster issues. You can iterate over the causes, rows, and last known server addresses via getNumExceptions(), getCause(int), getRow(int), and getHostnamePort(int).", "keywords": ["org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException"], "keywords_text": "org.apache.hadoop.hbase.client.RetriesExhaustedWithDetailsException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/index.html?org/apache/hadoop/hbase/client/RetriesExhaustedWithDetailsException.html"]}
{"issue_id": "hbase-1008", "component": "HBase", "summary": "Exception 'ServerNotRunningYetException: Server Is Not Running Yet' Generally Occurs When the Master Is Not Running or Initialized", "description": "Exception 'ServerNotRunningYetException: Server is not running yet' generally occurs when the master is not running or initialized. Please check the HBase master logs to confirm the actual root cause. This could be due to existing system procedures not being completed. Please check at which point the exception is coming.", "keywords": ["org.apache.hadoop.hbase.ipc.ServerNotRunningYetException", "Server is not running yet"], "keywords_text": "org.apache.hadoop.hbase.ipc.ServerNotRunningYetException Server is not running yet", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/ipc/ServerNotRunningYetException.html"]}
{"issue_id": "hbase-1009", "component": "HBase", "summary": "Thrown When Replay of WAL Is Required Because a Snapshot Was Not Properly Persisted", "description": "Thrown during a flush if the possibility exists that snapshot content was not properly persisted into store files. The response should include a replay of the WAL content. The region is put into closing mode, and the caller MUST abort after this.", "keywords": ["org.apache.hadoop.hbase.DroppedSnapshotException"], "keywords_text": "org.apache.hadoop.hbase.DroppedSnapshotException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/DroppedSnapshotException.html"]}
{"issue_id": "hbase-1010", "component": "HBase", "summary": "org.apache.hadoop.hbase.DoNotRetryIOException, Please Check for the Accompanying Exception", "description": "Thrown during an exception, and all other exceptions are subclasses of this parent class. Please check the exception, and initiate a retry of the same.", "keywords": ["org.apache.hadoop.hbase.DoNotRetryIOException"], "keywords_text": "org.apache.hadoop.hbase.DoNotRetryIOException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/index.html?org/apache/hadoop/hbase/DoNotRetryIOException.html"]}
{"issue_id": "hbase-1011", "component": "HBase", "summary": "HBase HBaseIOException Detected", "description": "All HBase-specific IOExceptions are part of this class. Please check the corresponding exception being generated to verify the root cause.", "keywords": ["org.apache.hadoop.hbase.HBaseIOException"], "keywords_text": "org.apache.hadoop.hbase.HBaseIOException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/class-use/HBaseIOException.html"]}
{"issue_id": "hbase-1012", "component": "HBase", "summary": "org.apache.hadoop.hbase.io.hfile.CorruptHFileException: The Underlying HFile May Be Corrupted", "description": "This exception is thrown when attempts to read an HFile fail due to corruption or truncation issues. Please check if the HFile is corrupted or not using the HFile tool (https://hbase.apache.org/book.html#hfile_tool).", "keywords": ["org.apache.hadoop.hbase.io.hfile.CorruptHFileException"], "keywords_text": "org.apache.hadoop.hbase.io.hfile.CorruptHFileException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/CorruptHFileException.html"]}
{"issue_id": "hbase-1013", "component": "HBase", "summary": "org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column Family Does Not Exist in Region", "description": "The exception is thrown when accessing a column family that does not exist for a table.", "keywords": ["org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException"], "keywords_text": "org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/NoSuchColumnFamilyException.html"]}
{"issue_id": "hbase-1014", "component": "HBase", "summary": "HRegionServer Aborted", "description": "The exception is thrown by the region server when it is aborting.", "keywords": ["org.apache.hadoop.hbase.regionserver.RegionServerAbortedException"], "keywords_text": "org.apache.hadoop.hbase.regionserver.RegionServerAbortedException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/regionserver/RegionServerAbortedException.html"]}
{"issue_id": "hbase-1015", "component": "HBase", "summary": "MasterNotRunningException Is Thrown When the HBase Master Is Not Running", "description": "Please check the HBase Active Master logs if there are any stuck procedures, regions in transition, or old ProcWALs holding the assignment. Based on the relevant error message, also check the ZooKeeper logs.", "keywords": ["org.apache.hadoop.hbase.MasterNotRunningException"], "keywords_text": "org.apache.hadoop.hbase.MasterNotRunningException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/class-use/MasterNotRunningException.html"]}
{"issue_id": "hbase-1016", "component": "HBase", "summary": "Please Check if There Are Too Many Requests in the System, and Need to Increase the Region Handler Count: hbase.regionserver.handler.count", "description": "Call queue is full on 0.0.0.0.16020? Returned to clients when their request was dropped because the call queue was too big to accept a new call. Clients should retry upon receiving it.", "keywords": ["org.apache.hadoop.hbase.CallQueueTooBigException"], "keywords_text": "org.apache.hadoop.hbase.CallQueueTooBigException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/CallQueueTooBigException.html"]}
{"issue_id": "hbase-1017", "component": "HBase", "summary": "Please Check Your Region Server Logs", "description": "This condition arises when ZooKeeper has informed the HBase master that the region server is dead, and the region server is still trying to connect to ZooKeeper on the same connection. A likely cause of this is GC pauses. This exception is thrown by the master when a region server reports and is already being processed as dead. This can happen when a region server loses its session but didn't figure it out yet.", "keywords": ["org.apache.hadoop.hbase.YouAreDeadException"], "keywords_text": "org.apache.hadoop.hbase.YouAreDeadException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/YouAreDeadException.html"]}
{"issue_id": "hbase-1018", "component": "HBase", "summary": "The Exception Occurs When a Client Is Trying to Create a Table That Already Exists", "description": "Thrown when a table exists but should not.", "keywords": ["org.apache.hadoop.hbase.TableExistsException"], "keywords_text": "org.apache.hadoop.hbase.TableExistsException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/TableExistsException.html"]}
{"issue_id": "hbase-1019", "component": "HBase", "summary": "This Exception Occurs When You Are Trying to Perform an Action on a Table That HBase Expects to Be Offline", "description": "Thrown if a table should be offline but is not. For example, if while dropping a table, and the table is enabled, it will throw the same exception.", "keywords": ["org.apache.hadoop.hbase.TableNotDisabledException"], "keywords_text": "org.apache.hadoop.hbase.TableNotDisabledException", "knowledge_center_links": ["https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/TableNotDisabledException.html"]}
{"issue_id": "hbase-1020", "component": "HBase", "summary": "The Following Exception Can Occur When We Are Trying to Work or Assign a Region That Does Not Exist in Meta", "description": "Thrown when we are asked to operate on a region we know nothing about. Please check the region ID.", "keywords": ["org.apache.hadoop.hbase.UnknownRegionException"], "keywords_text": "org.apache.hadoop.hbase.UnknownRegionException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/UnknownRegionException.html"]}
{"issue_id": "hbase-1021", "component": "HBase", "summary": "ERROR: org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException", "description": "Exception thrown when the found snapshot info from the file system is not valid. Please check snapshot integrity using the command: 'hbase snapshot info -snapshot <snapshot-name> -files'.", "keywords": ["org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException"], "keywords_text": "org.apache.hadoop.hbase.snapshot.CorruptedSnapshotException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/snapshot/CorruptedSnapshotException.html"]}
{"issue_id": "hbase-1022", "component": "HBase", "summary": "The Following Warning Can Occur When the BucketCache Size Is Less and the Block to Be Cached Is Not Able to Fit into the Cache", "description": "This class is used to allocate a block with a specified size and free the block when evicting. It manages an array of buckets, each bucket is associated with a size and caches elements up to this size. For a completely empty bucket, this size could be re-specified dynamically. Please see if the BucketCache size can be extended.", "keywords": ["org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocatorException"], "keywords_text": "org.apache.hadoop.hbase.io.hfile.bucket.BucketAllocatorException", "knowledge_center_links": ["https://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/bucket/BucketAllocatorException.html"]}
{"issue_id": "hbase-1023", "component": "HBase", "summary": "The Error Occurs on the Client Side If the Region Where the Request Is Made Is on a Region That Is Not Yet Active", "description": "Indicates that we're trying to connect to an already known as dead server. We will want to retry: we're getting this because the region location was wrong, or because the server just died, in which case the retry loop will help us to wait for the regions to recover. Please retry your operation, you may have to wait for the regions to be assigned to other region servers for the request to work.", "keywords": ["org.apache.hadoop.hbase.ipc.FailedServerException"], "keywords_text": "org.apache.hadoop.hbase.ipc.FailedServerException", "knowledge_center_links": ["https://hbase.apache.org/2.0/apidocs/org/apache/hadoop/hbase/ipc/FailedServerException.html"]}
{"issue_id": "hive-1001", "component": "Hive", "summary": "SemanticException Seen", "description": "SemanticException is thrown in the HIVE parser when the submitted HIVE query does not match proper semantics, or there is an issue with the resource in the query (table, partition, column does not exist). Please recheck the query, correct it, and run again. To find the exact query submitted to Hive, please check the Hive client or Hive-server logs on the EMR Master node.", "keywords": ["org.apache.hadoop.hive.ql.parse.SemanticException"], "keywords_text": "org.apache.hadoop.hive.ql.parse.SemanticException", "knowledge_center_links": ["https://repost.aws/knowledge-center/logs-hive-queries-amazon-emr"]}
{"issue_id": "hive-1002", "component": "Hive", "summary": "OutOfMemoryError on HIVE", "description": "The OutOfMemoryError exception usually happens when there's not enough heap space on the Hive-server2, the Hive metastore, or the client side. To resolve this issue, increase the maximum memory allocation for the JVM or increase HADOOP_HEAPSIZE. For more details, please see the KC article.", "keywords": ["java.lang.OutOfMemoryError"], "keywords_text": "java.lang.OutOfMemoryError", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-hive-outofmemoryerror-heap-space"]}
{"issue_id": "hive-1003", "component": "Hive", "summary": "HiveException Seen on the Application or Hive Server Logs", "description": "Exception happening when there is an error during Hive metadata retrieval or DDL operations. It can be thrown when Hive is trying to connect to the metastore and failing. Verify the Hive server logs for further information, as it can be seen for a number of different issues. See the KC article for an example.", "keywords": ["org.apache.hadoop.hive.ql.metadata.HiveException"], "keywords_text": "org.apache.hadoop.hive.ql.metadata.HiveException", "knowledge_center_links": [""]}
{"issue_id": "hive-1004", "component": "Hive", "summary": "HiveSQLException Seen on the Application or Hive Server Logs", "description": "Exception happening when there is an issue with an SQL query from Hive. It can be thrown if there is a syntax issue, NullPointerException, or any other issue with your query. See the KC article for an example.", "keywords": ["org.apache.hive.service.cli.HiveSQLException"], "keywords_text": "org.apache.hive.service.cli.HiveSQLException", "knowledge_center_links": [""]}
{"issue_id": "hive-1005", "component": "Hive", "summary": "HiveMetaException Seen on the Hive Metastore Logs", "description": "Exception thrown when there is an issue with the Hive Metastore Service, usually when the metastore fails to start. Verify the Hive Metastore logs for more information. See the two KC articles attached for examples (old articles though).", "keywords": ["org.apache.hadoop.hive.metastore.HiveMetaException"], "keywords_text": "org.apache.hadoop.hive.metastore.HiveMetaException", "knowledge_center_links": [""]}
{"issue_id": "hive-1006", "component": "Hive", "summary": "toSQLException Seen on the Application or Hive Server Logs", "description": "Can be seen in addition to the above (org.apache.hive.service.cli.HiveSQLException) thrown when there is an issue with the SQL query when parsing and preparing the statement. Verify if there aren't any issues with your query. Check the full error trace or Hive Server logs for more information.", "keywords": ["org.apache.hive.service.cli.operation.Operation.toSQLException"], "keywords_text": "org.apache.hive.service.cli.operation.Operation.toSQLException", "knowledge_center_links": [""]}
{"issue_id": "hive-1007", "component": "Hive", "summary": "MetaException Seen on the Logs", "description": "Exception coming from the Hive Metastore when there is an issue with it. Check the Hive metastore logs for more information. It can, for example, happen when the metastore database is not connecting.", "keywords": ["org.apache.hadoop.hive.metastore.api.MetaException"], "keywords_text": "org.apache.hadoop.hive.metastore.api.MetaException", "knowledge_center_links": [""]}
{"issue_id": "hive-1008", "component": "Hive", "summary": "HoodieHiveSyncException Detected", "description": "Happens where there is a metastore sync issue between Hudi and Hive. Usually when running the Hudi Sync tool for the Hive metastore. Review the rest of the error message for further information on what to fix.", "keywords": ["org.apache.hudi.hive.HoodieHiveSyncException"], "keywords_text": "org.apache.hudi.hive.HoodieHiveSyncException", "knowledge_center_links": [""]}
{"issue_id": "hive-1009", "component": "Hive", "summary": "org.apache.hadoop.hive.ql.parse.SemanticException Seen on Application or Hive Logs", "description": "SemanticException is thrown in the HIVE parser when the submitted HIVE query does not match proper semantics, or there is an issue with the resource in the query (table, partition, column does not exist). Please recheck the query, correct it, and run again. To find the exact query submitted to Hive, please check the Hive client or Hive-server logs on the EMR Master node.", "keywords": ["org.apache.hadoop.hive.ql.parse.SemanticException"], "keywords_text": "org.apache.hadoop.hive.ql.parse.SemanticException", "knowledge_center_links": [""]}
{"issue_id": "hive-1010", "component": "Hive", "summary": "HiveAccessControlException Detected", "description": "Exception is thrown when there is a permission issue with your Hive query, related to the table or database you are trying to access. Exception thrown by the Authorization plugin API (v2), indicating an authorization check denying permissions for an action.", "keywords": ["HiveAccessControlException"], "keywords_text": "HiveAccessControlException", "knowledge_center_links": [""]}
{"issue_id": "hive-1011", "component": "Hive", "summary": "org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException Detected on the Logs", "description": "Exception is thrown when there is an issue when reading the data of your Hive tables with RecordReader. The issue can, for example, be with the input data or throttling from Amazon S3. Review the rest of the error trace or check the Hive Server logs for further information.", "keywords": ["org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException"], "keywords_text": "org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException", "knowledge_center_links": [""]}
{"issue_id": "hive-1012", "component": "Hive", "summary": "com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.getHiveException Detected", "description": "Exception thrown when there is an issue when converting the Data Catalog from AWS Glue to the Hive Metastore. It can be due to various reasons, such as throttling on getPartitions or permission issues. Review the rest of the error logs for further information.", "keywords": ["com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.getHiveException"], "keywords_text": "com.amazonaws.glue.catalog.converters.CatalogToHiveConverter.getHiveException", "knowledge_center_links": [""]}
{"issue_id": "hive-1013", "component": "Hive", "summary": "org.apache.hadoop.hive.metastore.api.InvalidObjectException Detected", "description": "Exception thrown when there is an issue with the metadata. Usually on EMR, it is thrown when there is an issue with the operator and/or types used with your data when using the AWS Glue Data Catalog. Review the KC articles for more information.", "keywords": ["org.apache.hadoop.hive.metastore.api.InvalidObjectException"], "keywords_text": "org.apache.hadoop.hive.metastore.api.InvalidObjectException", "knowledge_center_links": [""]}
{"issue_id": "hive-1014", "component": "Hive", "summary": "org.apache.hive.com.esotericsoftware.kryo.KryoException Detected on the Logs", "description": "This exception is thrown when there is an issue during serialization. It can be due to bad data or a missing class. Read the full error log and/or check the HiveServer logs to understand the issue.", "keywords": ["org.apache.hive.com.esotericsoftware.kryo.KryoException"], "keywords_text": "org.apache.hive.com.esotericsoftware.kryo.KryoException", "knowledge_center_links": [""]}
{"issue_id": "hive-1015", "component": "Hive", "summary": "org.apache.hive.service.auth.HttpAuthenticationException Detected on the Logs", "description": "Exception thrown by the Thrift Server when there is an authentication error. It can be seen in the Hive Server logs. It can be due, for example, to an invalid ticket on a Kerberos-enabled cluster. Check the full error message for more information.", "keywords": ["org.apache.hive.service.auth.HttpAuthenticationException"], "keywords_text": "org.apache.hive.service.auth.HttpAuthenticationException", "knowledge_center_links": [""]}
{"issue_id": "hive-1016", "component": "Hive", "summary": "org.apache.hadoop.hive.serde2.SerDeException Detected", "description": "Exception thrown where there is an issue with the Serde. It can be due to multiple things; the rest of the error message can be more informative about the specific error (bad data, table definition, etc.). Example: java.lang.RuntimeException: MetaException(message:org.apache.hadoop.hive.serde2.SerDeException This table does not have the serde property 'input.regex'!)", "keywords": ["org.apache.hadoop.hive.serde2.SerDeException"], "keywords_text": "org.apache.hadoop.hive.serde2.SerDeException", "knowledge_center_links": [""]}
{"issue_id": "hive-1017", "component": "Hive", "summary": "org.apache.hadoop.hive.ql.parse.ParseException Detected", "description": "Exception thrown when there is an issue while the Hive parser was parsing your query. Verify the content of the query to solve the issue. Also, check the rest of the error message for further information on what to fix.", "keywords": ["org.apache.hadoop.hive.ql.parse.ParseException"], "keywords_text": "org.apache.hadoop.hive.ql.parse.ParseException", "knowledge_center_links": [""]}
{"issue_id": "hive-1018", "component": "Hive", "summary": "org.apache.hive.service.ServiceException Detected", "description": "Exception thrown by HiveServer when there is an issue with the Service itself. Usually thrown when HiveServer2 fails to start. Verify the example: org.apache.hive.service.ServiceException: Failed to Start HiveServer2.", "keywords": ["org.apache.hive.service.ServiceException"], "keywords_text": "org.apache.hive.service.ServiceException", "knowledge_center_links": [""]}
{"issue_id": "spark-1001", "component": "Spark", "summary": "Too Many Fetch Failures", "description": "The presence of 'Too many fetch-failures' or 'Error reading task output' error messages in step or task attempt logs indicates that the running task is dependent on the output of another task. This often occurs when a reduce task is queued to execute and requires the output of one or more map tasks, and the output is not yet available.", "keywords": ["org.apache.spark.shuffle.FetchFailedException", "FetchFailedException", "org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException"], "keywords_text": "org.apache.spark.shuffle.FetchFailedException FetchFailedException org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException", "knowledge_center_links": ["https://aws.amazon.com/blogs/big-data/spark-enhancements-for-elasticity-and-resiliency-on-amazon-emr/", "https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-error-resource-1.html"]}
{"issue_id": "spark-1002", "component": "Spark", "summary": "RpcTimeoutException", "description": "When the EMR Cluster nodes are under heavy load, RpcTimeoutException can occur. Timeout exceptions will occur when the executor is under memory constraint or facing OOM issues while processing data, impacting GC and causing further delay. Increase spark.executor.heartbeatInterval or specify a longer spark.network.timeout period.", "keywords": ["org.apache.spark.rpc.RpcTimeoutException", "Issue communicating with driver in heartbeater org.apache.spark.rpc.RpcTimeoutException"], "keywords_text": "org.apache.spark.rpc.RpcTimeoutException Issue communicating with driver in heartbeater org.apache.spark.rpc.RpcTimeoutException", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-troubleshoot-failed-spark-jobs"]}
{"issue_id": "spark-1003", "component": "Spark", "summary": "SPARK AnalysisException Detected", "description": "AnalysisException is thrown when a query fails to analyze, usually because the query itself is invalid.", "keywords": ["org.apache.spark.sql.AnalysisException"], "keywords_text": "org.apache.spark.sql.AnalysisException", "knowledge_center_links": [""]}
{"issue_id": "spark-1004", "component": "Spark", "summary": "Pyspark AnalysisException Detected", "description": "Pyspark AnalysisException is thrown when a query fails to analyze, usually because the query itself is invalid.", "keywords": ["pyspark.sql.utils.AnalysisException"], "keywords_text": "pyspark.sql.utils.AnalysisException", "knowledge_center_links": [""]}
{"issue_id": "spark-1005", "component": "Spark", "summary": "Spark App Failed with FileDownloadException", "description": "FileDownloadException is the generic error; it could be due to Amazon S3 issues like access denied, KMS keys, or EMRFS credentials. The root cause can be identified by observing the error stack trace and the corresponding exception linked to FileDownloadException.", "keywords": ["org.apache.spark.sql.execution.datasources.FileDownloadException: Failed to download file path"], "keywords_text": "org.apache.spark.sql.execution.datasources.FileDownloadException: Failed to download file path", "knowledge_center_links": [""]}
{"issue_id": "spark-1006", "component": "Spark", "summary": "Generic PythonException Detected", "description": "Please look for 'Traceback (most recent call last)'.", "keywords": ["org.apache.spark.api.python.PythonException"], "keywords_text": "org.apache.spark.api.python.PythonException", "knowledge_center_links": [""]}
{"issue_id": "spark-1007", "component": "Spark", "summary": "A Generic SparkException", "description": "A generic error was found. Check the log data for more details.", "keywords": ["org.apache.spark.SparkException"], "keywords_text": "org.apache.spark.SparkException", "knowledge_center_links": [""]}
{"issue_id": "spark-1008", "component": "Spark", "summary": "Spark History Events UI Issues Detected", "description": "On-cluster Spark History Server events are not accessible if you save the Spark events in an Amazon S3 bucket on Amazon EMR releases before 6.3 and 5.30. The Spark History Server in these Amazon EMR versions does not have the emrfs-hadoop-assembly JAR file required to access Amazon S3 buckets. Without this JAR file, you receive the following error when trying to access Spark History Server events.", "keywords": ["java.lang.ClassNotFoundException: Class com.amazon.ws.emr.hadoop.fs.EmrFileSystem not found"], "keywords_text": "java.lang.ClassNotFoundException: Class com.amazon.ws.emr.hadoop.fs.EmrFileSystem not found", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-view-spark-history-events"]}
{"issue_id": "spark-1009", "component": "Spark", "summary": "Failed Spark-Submit Job with Possible Executor Memory Issue", "description": "Indicates a memory problem. Please increase the executor memory using the --executor-memory option or spark.executor.memory in the Spark configuration.", "keywords": ["java.lang.IllegalArgumentException: Executor memory", "Please increase executor memory using the --executor-memory option or spark.executor.memory in Spark configuration"], "keywords_text": "java.lang.IllegalArgumentException: Executor memory Please increase executor memory using the --executor-memory option or spark.executor.memory in Spark configuration", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-view-spark-history-events"]}
{"issue_id": "spark-1010", "component": "Spark", "summary": "ClassNotFoundException Detected", "description": "The Spark job cannot find the relevant files in the classpath. When this happens, the class loader picks up only the JAR files that exist in the location that you specified in your configuration. Check the stack trace to find the name of the missing class. Then, add the path of your custom JAR (containing the missing class) to the Spark classpath. You can do this while the cluster is running, when you launch a new cluster, or when you submit a job.", "keywords": ["java.lang.ClassNotFoundException"], "keywords_text": "java.lang.ClassNotFoundException", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-spark-classnotfoundexception"]}
{"issue_id": "spark-1011", "component": "Spark", "summary": "Job Failure Detected Due to Stage or Task Failure", "description": "In Spark, stage failures happen when there is a problem with processing a Spark task. These failures can be caused by hardware issues, incorrect Spark configurations, or code problems.", "keywords": ["org.apache.spark.SparkException: Job aborted due to stage failure: Task", "ExecutorLostFailure", "failed 4 times, most recent failure: Lost task"], "keywords_text": "org.apache.spark.SparkException: Job aborted due to stage failure: Task ExecutorLostFailure failed 4 times, most recent failure: Lost task", "knowledge_center_links": [""]}
{"issue_id": "spark-1012", "component": "Spark", "summary": "Node Issues Detected", "description": "This error indicates that a Spark task failed because a node terminated or became unavailable. There are many possible causes of this error. The following resolution covers these common root causes: high disk utilization, using Spot Instances for cluster nodes, and aggressive auto-scaling policies.", "keywords": ["Lost task", "exited caused by one of the running tasks Reason: Slave lost"], "keywords_text": "Lost task exited caused by one of the running tasks Reason: Slave lost", "knowledge_center_links": ["https://repost.aws/knowledge-center/executorlostfailure-slave-lost-emr"]}
{"issue_id": "spark-1013", "component": "Spark", "summary": "Spark Applications on EMR Notebook Failures Detected", "description": "Spark applications running on the EMR notebook failing with a fatal error occur due to insufficient cluster resources, Livy server issues, or session timeout. Resolved by increasing driver memory, increasing the Livy server timeout, or restarting the kernel.", "keywords": ["The code failed because of a fatal error"], "keywords_text": "The code failed because of a fatal error", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-troubleshot-spark-apps"]}
{"issue_id": "spark-1014", "component": "Spark", "summary": "Containers Got Killed with Exit Code 137", "description": "When a container (Spark executor) runs out of memory, YARN automatically kills it. This causes the 'Container killed on request. Exit code is 137' error. These errors can happen in different job stages, both in narrow and wide transformations. YARN containers can also be killed by the OS oom_reaper when the OS is running out of memory, causing this error.", "keywords": ["Diagnostics: Container killed on request. Exit code is 137"], "keywords_text": "Diagnostics: Container killed on request. Exit code is 137", "knowledge_center_links": ["https://repost.aws/knowledge-center/container-killed-on-request-137-emr"]}
{"issue_id": "spark-1015", "component": "Spark", "summary": "Amazon S3 Throttling Detected", "description": "This error occurs when the Amazon Simple Storage Service (Amazon S3) request rate for your application exceeds the typically sustained rates of over 5,000 requests per second, and Amazon S3 internally optimizes performance.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Slow Down (Service: Amazon S3", "knowledge_center_links": ["https://aws.amazon.com/blogs/big-data/best-practices-to-optimize-data-access-performance-from-amazon-emr-and-aws-glue-to-amazon-s3/", "https://repost.aws/knowledge-center/emr-s3-503-slow-down"]}
{"issue_id": "spark-1016", "component": "Spark", "summary": "Disk Issues Detected", "description": "Spark uses local disks on the core and task nodes to store intermediate data. If the disks run out of space, then the job fails with a 'no space left on device' error. Use one of the following methods to resolve this error: add more Amazon Elastic Block Store (Amazon EBS) capacity, add more Spark partitions, or use a bootstrap action to dynamically scale up storage on the core and task nodes. For more information and an example bootstrap action script, see 'Dynamically scale up storage on Amazon EMR clusters'.", "keywords": ["No space left on device"], "keywords_text": "No space left on device", "knowledge_center_links": ["https://repost.aws/knowledge-center/no-space-left-on-device-emr-spark"]}
{"issue_id": "spark-1017", "component": "Spark", "summary": "Container Got Killed by YARN for Exceeding Memory Limits", "description": "The root cause and the appropriate solution for this error depend on your workload. You might have to try each of the following methods, in the following order, to troubleshoot the error: increase memory overhead, reduce the number of executor cores, increase the number of partitions, and increase driver and executor memory.", "keywords": ["Container killed by YARN for exceeding memory limits"], "keywords_text": "Container killed by YARN for exceeding memory limits", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-spark-yarn-memory-limit"]}
{"issue_id": "spark-1018", "component": "Spark", "summary": "ChunkFetchFailureException", "description": "The root cause is usually because the Executor (with the BlockManager for requested shuffle blocks) is lost and no longer available due to the node with shuffle data being in a decommissioned state due to unhealthy conditions, spot instance issues, or scale-down events.", "keywords": ["org.apache.spark.network.client.ChunkFetchFailureException"], "keywords_text": "org.apache.spark.network.client.ChunkFetchFailureException", "knowledge_center_links": [""]}
{"issue_id": "spark-1019", "component": "Spark", "summary": "Spark Job in Notebook or Studio Failed with 'Session Not Found' Error", "description": "This error usually happens when you keep the session running until it times out when running a Spark job through Livy using a Jupyter Notebook or Studio. The default value for livy.server.session.timeout is 1 hour. To resolve, increase the value of the livy.server.session.timeout property in /etc/livy/conf/livy.conf.", "keywords": ["404 from", "with error payload: session 0 not found"], "keywords_text": "404 from with error payload: session 0 not found", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-session-not-found-http-request-error"]}
{"issue_id": "spark-1020", "component": "Spark", "summary": "Broadcast Join Failures", "description": "This error occurs when a broadcast join takes too long, and the job times out during the broadcast join phase. Possible causes are that the broadcast was too large or the network was slow, which caused the broadcast to timeout. The solution is to increase the timeout for the broadcast (--conf spark.sql.broadcastTimeout=600s) or totally disable the broadcast join (--conf spark.sql.autoBroadcastJoinThreshold=-1).", "keywords": ["org.apache.spark.SparkException: Could not execute broadcast in 300 secs", "You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1"], "keywords_text": "org.apache.spark.SparkException: Could not execute broadcast in 300 secs You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1", "knowledge_center_links": [""]}
{"issue_id": "spark-1021", "component": "Spark", "summary": "Class org.apache.hadoop.fs.s3a.S3AFileSystem Not Found", "description": "The s3a filesystem is not recommended, and the suggestion is to leverage EMRFS (i.e., using the s3:// scheme instead of the s3a:// scheme).", "keywords": ["java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found"], "keywords_text": "java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found", "knowledge_center_links": ["https://repost.aws/questions/QUXO0H1bgKTWqiEYLEE-msAQ/executing-hive-create-table-in-spark-sql-java-lang-classnotfoundexception-class-org-apache-hadoop-fs-s3a-s3afilesystem-not-found"]}
{"issue_id": "spark-1022", "component": "Spark", "summary": "Spark Application Failed with 'Not Found' Error", "description": "This error indicates that an Amazon S3 file or path does not exist. The issue could be due to a missing file in Amazon S3. Before launching your application, confirm that you correctly entered the Amazon S3 path and that the path exists. This issue can occur when other applications or accounts are accessing the same Amazon S3 files. It's possible that the file or path was deleted by another application or account. Before launching your application, check if other applications or accounts are actively accessing the same Amazon S3 path.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Not Found", "Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found;"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Not Found Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found;", "knowledge_center_links": ["https://repost.aws/knowledge-center/emr-s3-404-not-found"]}
{"issue_id": "spark-1023", "component": "Spark", "summary": "Broadcast Join Limit Exceeded", "description": "8 GB is the limit, and it cannot be exceeded for a broadcast join in Spark. To resolve, disable the broadcast join (spark.sql.autoBroadcastJoinThreshold = -1) or avoid using broadcast hints in code with large data, or increase spark.sql.autoBroadcastJoinThreshold.", "keywords": ["org.apache.spark.SparkException: Cannot broadcast the table that is larger than"], "keywords_text": "org.apache.spark.SparkException: Cannot broadcast the table that is larger than", "knowledge_center_links": [""]}
{"issue_id": "spark-1024", "component": "Spark", "summary": "Spark App Failed with 'AM Container Launch Exit Code: 13'", "description": "Due to an issue with the AM Container launch, your Spark app has failed with Exit code: 13, which is a more generic exception. To mitigate this issue, packages in your applications must be compatible with the Spark version, application modules/dependencies should be deployed alongside the driver on the core nodes, and ensure the Python code's Spark context does not point to local or override the cluster mode.", "keywords": ["AM Container for app attempt", "exited with exitCode: 13", "Exception from container-launch. Exit code: 13"], "keywords_text": "AM Container for app attempt exited with exitCode: 13 Exception from container-launch. Exit code: 13", "knowledge_center_links": ["https://repost.aws/questions/QUFLPLPESJREqZ-yyZe92pjA/spark-submit-is-failing-in-cluster-mode-for-pyspark-application"]}
{"issue_id": "spark-1025", "component": "Spark", "summary": "MultiObjectDeleteException in Spark Job", "description": "It is caused when BATCH.DELETE.OBJECT is performed. To delete a whole folder, EMRFS will list all the objects in the folder and use the deleteAll() to delete all the keys in one Amazon S3 request. The root cause can be many of the following reasons, such as Amazon S3 throttling, Amazon S3 access denied, issues with the s3a filesystem, or any known issues in a specific EMR version.", "keywords": ["com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.MultiObjectDeleteException: One or more objects could not be deleted"], "keywords_text": "com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.MultiObjectDeleteException: One or more objects could not be deleted", "knowledge_center_links": [""]}
{"issue_id": "spark-1026", "component": "Spark", "summary": "Unable to Query a Table in Spark SQL Using AWS Lake Formation", "description": "This issue is encountered when there is an access issue when trying to access the AWS Glue Data Catalog managed by AWS Lake Formation access control.", "keywords": ["org.apache.spark.sql.catalyst.analysis.AccessControlException"], "keywords_text": "org.apache.spark.sql.catalyst.analysis.AccessControlException", "knowledge_center_links": ["https://repost.aws/knowledge-center/glue-insufficient-lakeformation-permissions"]}
{"issue_id": "spark-1027", "component": "Spark", "summary": "Total Size of Serialized Results of Tasks Is Bigger Than spark.driver.maxResultSize", "description": "The spark.driver.maxResultSize property defines the limit of the total size of serialized results of all partitions for each Spark action (e.g., collect) in bytes. This issue can also occur when broadcasting a table that is too big. Spark downloads all the rows for a table that needs to be broadcasted to the driver before it starts shipping to the executors. If broadcasting a table that is larger than spark.driver.maxResultSize causes such issues, increasing spark.driver.maxResultSize helps, but if you set a high limit, an OutOfMemoryError can occur.", "keywords": ["Job aborted due to stage failure: Total size of serialized results of tasks is bigger than spark.driver.maxResultSize"], "keywords_text": "Job aborted due to stage failure: Total size of serialized results of tasks is bigger than spark.driver.maxResultSize", "knowledge_center_links": [""]}
{"issue_id": "spark-1028", "component": "Spark", "summary": "Block Not Found Exceptions", "description": "Spark shuffle blocks are managed by the NodeManager. If there are any issues with the NodeManager like an OutOfMemoryError or restart, this issue occurs. Also, check if there are any issues with the node with the corresponding NodeManager.", "keywords": ["org.apache.spark.storage.BlockNotFoundException", "org.apache.spark.SparkException: Failed to get broadcast_piece"], "keywords_text": "org.apache.spark.storage.BlockNotFoundException org.apache.spark.SparkException: Failed to get broadcast_piece", "knowledge_center_links": [""]}
{"issue_id": "spark-1029", "component": "Spark", "summary": "Spark Job Failed with Exit Code 1", "description": "The container was stopped due to an application error. Exit Code 1 indicates that a container shut down, either because of an application failure, issues with user code or script. It can also occur if there are incorrect arguments in the spark-submit command in cluster mode.", "keywords": ["org.apache.spark.SparkUserAppException: User application exited with 1"], "keywords_text": "org.apache.spark.SparkUserAppException: User application exited with 1", "knowledge_center_links": [""]}
{"issue_id": "spark-1030", "component": "Spark", "summary": "Application Failed with Upgrade Exception", "description": "This is a limitation on Spark version 3.0 with the old date and timestamp value results. When you read or write dates before 1582-10-15 or timestamps before 1900-01-01T00:00:00Z into Parquet files, the resultant values are erroneous. Set spark.sql.legacy.parquet.datetimeRebaseModeInWrite to LEGACY and spark.sql.legacy.parquet.datetimeRebaseModeInWrite to CORRECTED.", "keywords": ["org.apache.spark.SparkUpgradeException", "You may get a different result due to the upgrading of Spark 3.0"], "keywords_text": "org.apache.spark.SparkUpgradeException You may get a different result due to the upgrading of Spark 3.0", "knowledge_center_links": [""]}
{"issue_id": "presto-1001", "component": "Presto", "summary": "PrestoException Detected", "description": "This is a generic Presto error, and there are many reasons this exception can occur. Check the following log message to understand the root cause.", "keywords": ["com.facebook.presto.spi.PrestoException"], "keywords_text": "com.facebook.presto.spi.PrestoException", "knowledge_center_links": [""]}
{"issue_id": "presto-1002", "component": "Presto", "summary": "ResultsException Detected", "description": "Exception is related to the directory structure expected by Presto for bucketed tables.", "keywords": ["com.facebook.presto.jdbc.PrestoResultSet.resultsException"], "keywords_text": "com.facebook.presto.jdbc.PrestoResultSet.resultsException", "knowledge_center_links": [""]}
{"issue_id": "presto-1003", "component": "Presto", "summary": "Presto PageTransportTimeoutException Detected", "description": "This exception is primarily for big queries which deal with a huge amount of data in join statements.", "keywords": ["com.facebook.presto.operator.PageTransportTimeoutException"], "keywords_text": "com.facebook.presto.operator.PageTransportTimeoutException", "knowledge_center_links": [""]}
{"issue_id": "presto-1004", "component": "Presto", "summary": "PrestoException Detected When Connecting to Trino Using Custom SQL", "description": "This is a generic Presto error, and there are many reasons this exception can occur. Check the following log message to understand the root cause.", "keywords": ["io.prestosql.spi.PrestoException"], "keywords_text": "io.prestosql.spi.PrestoException", "knowledge_center_links": [""]}
{"issue_id": "presto-1005", "component": "Presto", "summary": "ParsingException Detected Related to Semantics While Writing Presto Query", "description": "This exception occurs if the query (SQL) is not delimited properly or if there is any typo while running the Presto query, mostly occurring due to semicolons, commas, etc.", "keywords": ["com.facebook.presto.sql.parser.ParsingException"], "keywords_text": "com.facebook.presto.sql.parser.ParsingException", "knowledge_center_links": [""]}
{"issue_id": "presto-1006", "component": "Presto", "summary": "Related to Load or Network Issue", "description": "Presto worker nodes might be having resource contention on CPU or memory, which ultimately causes an issue while reading, writing, fetching data from other nodes, or overall Presto communication.", "keywords": ["com.facebook.presto.spi.PrestoTransportException"], "keywords_text": "com.facebook.presto.spi.PrestoTransportException", "knowledge_center_links": [""]}
{"issue_id": "presto-1007", "component": "Presto", "summary": "Exceptions Related to Datatype Mismatch", "description": "Implementation of the ResultSet class which is related to the datatype used (e.g., VARCHAR). When the value cannot be converted, we get this kind of exception.", "keywords": ["io.prestosql.jdbc.AbstractPrestoResultSet.resultsException"], "keywords_text": "io.prestosql.jdbc.AbstractPrestoResultSet.resultsException", "knowledge_center_links": [""]}
{"issue_id": "presto-1008", "component": "Presto", "summary": "More Memory Is Being Used", "description": "This exception occurs when a Presto query is running and demands more memory at different stages, e.g., due to data skew or a task-concurrency factor.", "keywords": ["com.facebook.presto.ExceededMemoryLimitException"], "keywords_text": "com.facebook.presto.ExceededMemoryLimitException", "knowledge_center_links": [""]}
{"issue_id": "presto-1009", "component": "Presto", "summary": "Not a Valid Parquet File", "description": "This exception is encountered when there is an issue with the Parquet file structure.", "keywords": ["com.facebook.presto.parquet.ParquetCorruptionException"], "keywords_text": "com.facebook.presto.parquet.ParquetCorruptionException", "knowledge_center_links": [""]}
{"issue_id": "presto-1010", "component": "Presto", "summary": "No Permissions on Presto Tables", "description": "This exception occurs mostly due to insufficient permissions or while performing some action on Hive tables as the Presto user.", "keywords": ["com.facebook.presto.spi.security.AccessDeniedException"], "keywords_text": "com.facebook.presto.spi.security.AccessDeniedException", "knowledge_center_links": [""]}
{"issue_id": "presto-1011", "component": "Presto", "summary": "Mismatch in SQL Parameters", "description": "This exception is mostly due to column mismatch, parameter mismatch, or datatype mismatch in the query.", "keywords": ["com.facebook.presto.sql.analyzer.SemanticException"], "keywords_text": "com.facebook.presto.sql.analyzer.SemanticException", "knowledge_center_links": [""]}
{"issue_id": "presto-1012", "component": "Presto", "summary": "Table Does Not Exist", "description": "When there is a table name mismatch.", "keywords": ["com.facebook.presto.spi.TableNotFoundException"], "keywords_text": "com.facebook.presto.spi.TableNotFoundException", "knowledge_center_links": [""]}
{"issue_id": "presto-1013", "component": "Presto", "summary": "Access Denied or Permission Issue", "description": "This exception is mostly due to table permissions set by the table owner or group, e.g., column or database/table name.", "keywords": ["io.prestosql.spi.security.AccessDeniedException"], "keywords_text": "io.prestosql.spi.security.AccessDeniedException", "knowledge_center_links": [""]}
{"issue_id": "presto-1014", "component": "Presto", "summary": "No Connection to Hive Metastore", "description": "When Presto loses connection to or is not able to connect to the Hive Metastore, we get this exception.", "keywords": ["com.facebook.presto.hive.metastore.thrift.Transport.rewriteException"], "keywords_text": "com.facebook.presto.hive.metastore.thrift.Transport.rewriteException", "knowledge_center_links": [""]}
{"issue_id": "presto-1015", "component": "Presto", "summary": "Due to Corrupt Statistics", "description": "Fail queries reading Parquet files if statistics in those Parquet files are corrupt (e.g., min > max). To disable this behavior, set the configuration property 'hive.parquet.fail-on-corrupted-statistics' or session property 'parquet_fail_with_corrupted_statistics' to false.", "keywords": ["com.facebook.presto.parquet.predicate.TupleDomainParquetPredicate.failWithCorruptionException"], "keywords_text": "com.facebook.presto.parquet.predicate.TupleDomainParquetPredicate.failWithCorruptionException", "knowledge_center_links": [""]}
{"issue_id": "presto-1016", "component": "Presto", "summary": "While Fetching Response from Worker Node", "description": "This exception is mostly due to a long-running query when it fails to send or receive internal requests because of connection issues.", "keywords": ["com.facebook.presto.jdbc.internal.client.StatementClientV1.requestFailedException"], "keywords_text": "com.facebook.presto.jdbc.internal.client.StatementClientV1.requestFailedException", "knowledge_center_links": [""]}
{"issue_id": "presto-1017", "component": "Presto", "summary": "Access Denied Exception or Permission Issue", "description": "Mostly related to how users or groups can access the Presto catalog.", "keywords": ["io.prestosql.spi.security.AccessDeniedException.denyCatalogAccess"], "keywords_text": "io.prestosql.spi.security.AccessDeniedException.denyCatalogAccess", "knowledge_center_links": ["https://issues.apache.org/jira/browse/RANGER-3142?page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel&focusedCommentId=17468378#comment-17468378"]}
{"issue_id": "presto-1018", "component": "Presto", "summary": "Connection Being Refused by Presto Worker Node", "description": "This exception is thrown while handling a JSON response, mostly due to some configuration mismatch or invalid response. Check any custom class implemented by the user.", "keywords": ["com.facebook.presto.server.smile.AdaptingJsonResponseHandler.handleException"], "keywords_text": "com.facebook.presto.server.smile.AdaptingJsonResponseHandler.handleException", "knowledge_center_links": [""]}
{"issue_id": "presto-1019", "component": "Presto", "summary": "When Query Exceeds Per-Node Memory", "description": "This is the exception when the memory per node exceeds more than what it is set to.", "keywords": ["io.prestosql.ExceededMemoryLimitException"], "keywords_text": "io.prestosql.ExceededMemoryLimitException", "knowledge_center_links": [""]}
{"issue_id": "presto-1020", "component": "Presto", "summary": "Access Table Content", "description": "This exception occurs mostly due to table operations that are not permitted on Hive tables by Presto, possibly due to user or group-level permissions.", "keywords": ["com.facebook.presto.spi.security.AccessDeniedException.denySelectTable"], "keywords_text": "com.facebook.presto.spi.security.AccessDeniedException.denySelectTable", "knowledge_center_links": ["https://github.com/prestodb/presto/issues/7773"]}
{"issue_id": "presto-1021", "component": "Presto", "summary": "Connection Issue - Presto JVM on Primary Instance", "description": "This exception occurs when the Presto coordinator refuses connections from clients, mostly due to being overloaded. Make sure that the Presto JVM has enough memory to serve incoming connections.", "keywords": ["com.facebook.presto.jdbc.internal.airlift.http.client.RuntimeIOException"], "keywords_text": "com.facebook.presto.jdbc.internal.airlift.http.client.RuntimeIOException", "knowledge_center_links": [""]}
{"issue_id": "presto-1022", "component": "Presto", "summary": "When File Is Not Present in Amazon S3", "description": "This exception occurs when Amazon S3 metadata is not synced or when EMRFS consistent view is disabled.", "keywords": ["com.facebook.presto.hive.s3.PrestoS3FileSystem.UnrecoverableS3OperationException"], "keywords_text": "com.facebook.presto.hive.s3.PrestoS3FileSystem.UnrecoverableS3OperationException", "knowledge_center_links": [""]}
{"issue_id": "presto-1023", "component": "Presto", "summary": "Remote Service Is Not Available", "description": "This is probably a transient issue or exception when Presto is not able to talk to some remote service due to a network issue. Or this can be a classic load on the JVM issue.", "keywords": ["com.facebook.presto.server.remotetask.SimpleHttpResponseHandler.ServiceUnavailableException"], "keywords_text": "com.facebook.presto.server.remotetask.SimpleHttpResponseHandler.ServiceUnavailableException", "knowledge_center_links": [""]}
